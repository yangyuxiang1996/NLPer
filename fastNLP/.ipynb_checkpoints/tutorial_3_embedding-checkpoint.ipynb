{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 out of 7 words in the pre-training embedding.\n",
      "torch.Size([1, 5, 50])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/distiller/project/conda/conda-bld/pytorch_1591914925853/work/aten/src/ATen/native/TensorFactories.cpp:361: UserWarning: Deprecation warning: In a future PyTorch release torch.full will no longer return tensors of floating dtype by default. Instead, a bool fill_value will return a tensor of torch.bool dtype, and an integral fill_value will return a tensor of torch.long dtype. Set the optional `dtype` or `out` arguments to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from fastNLP.embeddings import StaticEmbedding\n",
    "from fastNLP import Vocabulary\n",
    "\n",
    "vocab = Vocabulary()\n",
    "vocab.add_word_lst(\"this is a demo .\".split())\n",
    "\n",
    "embed = StaticEmbedding(vocab, model_dir_or_name='en-glove-6b-50d')\n",
    "\n",
    "words = torch.LongTensor([[vocab.to_index(word) for word in \"this is a demo .\".split()]])  # 将文本转为index\n",
    "print(embed(words).size())  # StaticEmbedding的使用和pytorch的nn.Embedding是类似的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 5.3074e-01,  4.0117e-01, -4.0785e-01,  1.5444e-01,  4.7782e-01,\n",
      "           2.0754e-01, -2.6951e-01, -3.4023e-01, -1.0879e-01,  1.0563e-01,\n",
      "          -1.0289e-01,  1.0849e-01, -4.9681e-01, -2.5128e-01,  8.4025e-01,\n",
      "           3.8949e-01,  3.2284e-01, -2.2797e-01, -4.4342e-01, -3.1649e-01,\n",
      "          -1.2406e-01, -2.8170e-01,  1.9467e-01,  5.5513e-02,  5.6705e-01,\n",
      "          -1.7419e+00, -9.1145e-01,  2.7036e-01,  4.1927e-01,  2.0279e-02,\n",
      "           4.0405e+00, -2.4943e-01, -2.0416e-01, -6.2762e-01, -5.4783e-02,\n",
      "          -2.6883e-01,  1.8444e-01,  1.8204e-01, -2.3536e-01, -1.6155e-01,\n",
      "          -2.7655e-01,  3.5506e-02, -3.8211e-01, -7.5134e-04, -2.4822e-01,\n",
      "           2.8164e-01,  1.2819e-01,  2.8762e-01,  1.4440e-01,  2.3611e-01],\n",
      "         [ 6.1850e-01,  6.4254e-01, -4.6552e-01,  3.7570e-01,  7.4838e-01,\n",
      "           5.3739e-01,  2.2239e-03, -6.0577e-01,  2.6408e-01,  1.1703e-01,\n",
      "           4.3722e-01,  2.0092e-01, -5.7859e-02, -3.4589e-01,  2.1664e-01,\n",
      "           5.8573e-01,  5.3919e-01,  6.9490e-01, -1.5618e-01,  5.5830e-02,\n",
      "          -6.0515e-01, -2.8997e-01, -2.5594e-02,  5.5593e-01,  2.5356e-01,\n",
      "          -1.9612e+00, -5.1381e-01,  6.9096e-01,  6.6246e-02, -5.4224e-02,\n",
      "           3.7871e+00, -7.7403e-01, -1.2689e-01, -5.1465e-01,  6.6705e-02,\n",
      "          -3.2933e-01,  1.3483e-01,  1.9049e-01,  1.3812e-01, -2.1503e-01,\n",
      "          -1.6573e-02,  3.1200e-01, -3.3189e-01, -2.6001e-02, -3.8203e-01,\n",
      "           1.9403e-01, -1.2466e-01, -2.7557e-01,  3.0899e-01,  4.8497e-01],\n",
      "         [ 2.1705e-01,  4.6515e-01, -4.6757e-01,  1.0082e-01,  1.0135e+00,\n",
      "           7.4845e-01, -5.3104e-01, -2.6256e-01,  1.6812e-01,  1.3182e-01,\n",
      "          -2.4909e-01, -4.4185e-01, -2.1739e-01,  5.1004e-01,  1.3448e-01,\n",
      "          -4.3141e-01, -3.1230e-02,  2.0674e-01, -7.8138e-01, -2.0148e-01,\n",
      "          -9.7401e-02,  1.6088e-01, -6.1836e-01, -1.8504e-01, -1.2461e-01,\n",
      "          -2.2526e+00, -2.2321e-01,  5.0430e-01,  3.2257e-01,  1.5313e-01,\n",
      "           3.9636e+00, -7.1365e-01, -6.7012e-01,  2.8388e-01,  2.1738e-01,\n",
      "           1.4433e-01,  2.5926e-01,  2.3434e-01,  4.2740e-01, -4.4451e-01,\n",
      "           1.3813e-01,  3.6973e-01, -6.4289e-01,  2.4142e-02, -3.9315e-02,\n",
      "          -2.6037e-01,  1.2017e-01, -4.3782e-02,  4.1013e-01,  1.7960e-01],\n",
      "         [-1.7803e-01, -1.7302e-01,  5.8694e-01, -1.8570e-01, -5.9242e-01,\n",
      "           1.8338e-02, -6.5556e-01, -7.0627e-02, -3.3047e-01,  1.4527e+00,\n",
      "           1.0392e-01, -4.1028e-01, -3.2541e-01,  8.0382e-01,  6.6078e-01,\n",
      "          -5.8436e-01, -4.4000e-01,  2.0930e-02,  3.8267e-02, -2.2063e-02,\n",
      "           4.0413e-01,  4.2170e-01,  6.9640e-01,  3.8701e-01,  2.1013e-01,\n",
      "           5.1746e-01, -5.3638e-01,  6.5909e-03, -1.5586e-01, -4.9149e-01,\n",
      "           1.9253e+00, -9.6846e-01, -6.3483e-01,  7.4755e-02,  2.3455e-01,\n",
      "           8.3168e-01,  1.5684e+00, -7.4541e-01, -7.1869e-01, -8.9761e-01,\n",
      "           5.9279e-01, -8.9022e-01, -1.1753e+00, -9.1221e-01,  2.4742e-01,\n",
      "           6.1200e-02,  4.7772e-01,  1.2265e-01, -4.6305e-01, -5.2186e-01],\n",
      "         [ 1.5164e-01,  3.0177e-01, -1.6763e-01,  1.7684e-01,  3.1719e-01,\n",
      "           3.3973e-01, -4.3478e-01, -3.1086e-01, -4.4999e-01, -2.9486e-01,\n",
      "           1.6608e-01,  1.1963e-01, -4.1328e-01, -4.2353e-01,  5.9868e-01,\n",
      "           2.8825e-01, -1.1547e-01, -4.1848e-02, -6.7989e-01, -2.5063e-01,\n",
      "           1.8472e-01,  8.6876e-02,  4.6582e-01,  1.5035e-02,  4.3474e-02,\n",
      "          -1.4671e+00, -3.0384e-01, -2.3441e-02,  3.0589e-01, -2.1785e-01,\n",
      "           3.7460e+00,  4.2284e-03, -1.8436e-01, -4.6209e-01,  9.8329e-02,\n",
      "          -1.1907e-01,  2.3919e-01,  1.1610e-01,  4.1705e-01,  5.6763e-02,\n",
      "          -6.3681e-05,  6.8987e-02,  8.7939e-02, -1.0285e-01, -1.3931e-01,\n",
      "           2.2314e-01, -8.0803e-02, -3.5652e-01,  1.6413e-02,  1.0216e-01]]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(embed(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 30])\n"
     ]
    }
   ],
   "source": [
    "from fastNLP.embeddings import StaticEmbedding\n",
    "from fastNLP import Vocabulary\n",
    "\n",
    "vocab = Vocabulary()\n",
    "vocab.add_word_lst(\"this is a demo .\".split())\n",
    "\n",
    "embed = StaticEmbedding(vocab, model_dir_or_name=None, embedding_dim=30)\n",
    "\n",
    "words = torch.LongTensor([[vocab.to_index(word) for word in \"this is a demo .\".split()]])\n",
    "print(embed(words).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 81.9k/408M [00:00<09:22, 725kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://212.129.155.247/embedding/bert-base-uncased.zip not found in cache, downloading to /var/folders/1t/r3byrg0s5cb80qkz17dn8nc40000gn/T/tmp9bt__3z5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 408M/408M [10:27<00:00, 650kB/s]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish download from http://212.129.155.247/embedding/bert-base-uncased.zip\n",
      "Copy file to /Users/mac/.fastNLP/embedding/bert-base-uncased\n",
      "loading vocabulary file /Users/mac/.fastNLP/embedding/bert-base-uncased/vocab.txt\n",
      "Load pre-trained BERT parameters from file /Users/mac/.fastNLP/embedding/bert-base-uncased/pytorch_model.bin.\n",
      "Start to generate word pieces for word.\n",
      "Found(Or segment into word pieces) 7 words out of 7.\n",
      "torch.Size([1, 5, 768])\n"
     ]
    }
   ],
   "source": [
    "from fastNLP.embeddings import ElmoEmbedding, BertEmbedding\n",
    "from fastNLP import Vocabulary\n",
    "\n",
    "vocab = Vocabulary()\n",
    "vocab.add_word_lst(\"this is a demo .\".split())\n",
    "\n",
    "embed = BertEmbedding(vocab, model_dir_or_name='en-base-uncased', requires_grad=False)\n",
    "words = torch.LongTensor([[vocab.to_index(word) for word in \"this is a demo .\".split()]])\n",
    "print(embed(words).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastNLP.embeddings import ElmoEmbedding, BertEmbedding\n",
    "from fastNLP import Vocabulary\n",
    "\n",
    "vocab = Vocabulary()\n",
    "vocab.add_word_lst(\"this is a demo .\".split())\n",
    "\n",
    "embed = ElmoEmbedding(vocab, model_dir_or_name='en-small', requires_grad=False)\n",
    "words = torch.LongTensor([[vocab.to_index(word) for word in \"this is a demo .\".split()]])\n",
    "print(embed(words).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 out of 22 characters were found in pretrained elmo embedding.\n",
      "torch.Size([1, 5, 512])\n"
     ]
    }
   ],
   "source": [
    "embed = ElmoEmbedding(vocab, model_dir_or_name='en-small', requires_grad=False, layers='1,2')\n",
    "print(embed(words).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 out of 22 characters were found in pretrained elmo embedding.\n",
      "torch.Size([1, 5, 256])\n"
     ]
    }
   ],
   "source": [
    "embed = ElmoEmbedding(vocab, model_dir_or_name='en-small', requires_grad=True, layers='mix')\n",
    "print(embed(words).size())  # 三层输出按照权重element-wise的加起来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vocabulary file /remote-home/ynzheng/.fastNLP/embedding/bert-base-cased/vocab.txt\n",
      "Load pre-trained BERT parameters from file /remote-home/ynzheng/.fastNLP/embedding/bert-base-cased/pytorch_model.bin.\n",
      "Start to generate word pieces for word.\n",
      "Found(Or segment into word pieces) 7 words out of 7.\n",
      "torch.Size([1, 5, 768])\n"
     ]
    }
   ],
   "source": [
    "from fastNLP.embeddings import BertEmbedding\n",
    "from fastNLP import Vocabulary\n",
    "\n",
    "vocab = Vocabulary()\n",
    "vocab.add_word_lst(\"this is a demo .\".split())\n",
    "\n",
    "embed = BertEmbedding(vocab, model_dir_or_name='en-base-cased')\n",
    "words = torch.LongTensor([[vocab.to_index(word) for word in \"this is a demo .\".split()]])\n",
    "print(embed(words).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vocabulary file /remote-home/ynzheng/.fastNLP/embedding/bert-base-cased/vocab.txt\n",
      "Load pre-trained BERT parameters from file /remote-home/ynzheng/.fastNLP/embedding/bert-base-cased/pytorch_model.bin.\n",
      "Start to generate word pieces for word.\n",
      "Found(Or segment into word pieces) 7 words out of 7.\n",
      "torch.Size([1, 5, 1536])\n"
     ]
    }
   ],
   "source": [
    "#  使用后面两层的输出\n",
    "embed = BertEmbedding(vocab, model_dir_or_name='en-base-cased', layers='10,11')\n",
    "print(embed(words).size())  # 结果将是在最后一维做拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vocabulary file /remote-home/ynzheng/.fastNLP/embedding/bert-base-cased/vocab.txt\n",
      "Load pre-trained BERT parameters from file /remote-home/ynzheng/.fastNLP/embedding/bert-base-cased/pytorch_model.bin.\n",
      "Start to generate word pieces for word.\n",
      "Found(Or segment into word pieces) 7 words out of 7.\n",
      "torch.Size([1, 7, 768])\n"
     ]
    }
   ],
   "source": [
    "embed = BertEmbedding(vocab, model_dir_or_name='en-base-cased', layers='-1', include_cls_sep=True)\n",
    "print(embed(words).size())  # 结果将在序列维度上增加2\n",
    "# 取出句子的cls表示\n",
    "cls_reps = embed(words)[:, 0]  # shape: [batch_size, 768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vocabulary file /remote-home/ynzheng/.fastNLP/embedding/bert-base-cased/vocab.txt\n",
      "Load pre-trained BERT parameters from file /remote-home/ynzheng/.fastNLP/embedding/bert-base-cased/pytorch_model.bin.\n",
      "Start to generate word pieces for word.\n",
      "Found(Or segment into word pieces) 7 words out of 7.\n",
      "torch.Size([1, 5, 768])\n"
     ]
    }
   ],
   "source": [
    "embed = BertEmbedding(vocab, model_dir_or_name='en-base-cased', layers='-1', pool_method='max')\n",
    "print(embed(words).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vocabulary file /remote-home/ynzheng/.fastNLP/embedding/bert-base-cased/vocab.txt\n",
      "Load pre-trained BERT parameters from file /remote-home/ynzheng/.fastNLP/embedding/bert-base-cased/pytorch_model.bin.\n",
      "Start to generate word pieces for word.\n",
      "Found(Or segment into word pieces) 10 words out of 10.\n",
      "torch.Size([1, 9, 768])\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary()\n",
    "vocab.add_word_lst(\"this is a demo . [SEP] another sentence .\".split())\n",
    "\n",
    "embed = BertEmbedding(vocab, model_dir_or_name='en-base-cased', layers='-1', pool_method='max')\n",
    "words = torch.LongTensor([[vocab.to_index(word) for word in \"this is a demo . [SEP] another sentence .\".split()]])\n",
    "print(embed(words).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start constructing character vocabulary.\n",
      "In total, there are 8 distinct characters.\n",
      "torch.Size([1, 5, 64])\n"
     ]
    }
   ],
   "source": [
    "from fastNLP.embeddings import CNNCharEmbedding\n",
    "from fastNLP import Vocabulary\n",
    "\n",
    "vocab = Vocabulary()\n",
    "vocab.add_word_lst(\"this is a demo .\".split())\n",
    "\n",
    "# character的embedding维度大小为50，返回的embedding结果维度大小为64。\n",
    "embed = CNNCharEmbedding(vocab, embed_size=64, char_emb_size=50)\n",
    "words = torch.LongTensor([[vocab.to_index(word) for word in \"this is a demo .\".split()]])\n",
    "print(embed(words).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start constructing character vocabulary.\n",
      "In total, there are 8 distinct characters.\n",
      "torch.Size([1, 5, 64])\n"
     ]
    }
   ],
   "source": [
    "from fastNLP.embeddings import LSTMCharEmbedding\n",
    "from fastNLP import Vocabulary\n",
    "\n",
    "vocab = Vocabulary()\n",
    "vocab.add_word_lst(\"this is a demo .\".split())\n",
    "\n",
    "# character的embedding维度大小为50，返回的embedding结果维度大小为64。\n",
    "embed = LSTMCharEmbedding(vocab, embed_size=64, char_emb_size=50)\n",
    "words = torch.LongTensor([[vocab.to_index(word) for word in \"this is a demo .\".split()]])\n",
    "print(embed(words).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 out of 7 words in the pre-training embedding.\n",
      "50\n",
      "Start constructing character vocabulary.\n",
      "In total, there are 8 distinct characters.\n",
      "30\n",
      "22 out of 22 characters were found in pretrained elmo embedding.\n",
      "256\n",
      "22 out of 22 characters were found in pretrained elmo embedding.\n",
      "512\n",
      "loading vocabulary file /remote-home/ynzheng/.fastNLP/embedding/bert-base-cased/vocab.txt\n",
      "Load pre-trained BERT parameters from file /remote-home/ynzheng/.fastNLP/embedding/bert-base-cased/pytorch_model.bin.\n",
      "Start to generate word pieces for word.\n",
      "Found(Or segment into word pieces) 7 words out of 7.\n",
      "768\n",
      "loading vocabulary file /remote-home/ynzheng/.fastNLP/embedding/bert-base-cased/vocab.txt\n",
      "Load pre-trained BERT parameters from file /remote-home/ynzheng/.fastNLP/embedding/bert-base-cased/pytorch_model.bin.\n",
      "Start to generate word pieces for word.\n",
      "Found(Or segment into word pieces) 7 words out of 7.\n",
      "1536\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "from fastNLP.embeddings import *\n",
    "\n",
    "vocab = Vocabulary()\n",
    "vocab.add_word_lst(\"this is a demo .\".split())\n",
    "\n",
    "static_embed = StaticEmbedding(vocab, model_dir_or_name='en-glove-6b-50d')\n",
    "print(static_embed.embedding_dim)  # 50\n",
    "char_embed = CNNCharEmbedding(vocab, embed_size=30)\n",
    "print(char_embed.embedding_dim)    # 30\n",
    "elmo_embed_1 = ElmoEmbedding(vocab, model_dir_or_name='en-small', layers='2')\n",
    "print(elmo_embed_1.embedding_dim)  # 256\n",
    "elmo_embed_2 = ElmoEmbedding(vocab, model_dir_or_name='en-small', layers='1,2')\n",
    "print(elmo_embed_2.embedding_dim)  # 512\n",
    "bert_embed_1 = BertEmbedding(vocab, layers='-1', model_dir_or_name='en-base-cased')\n",
    "print(bert_embed_1.embedding_dim)  # 768\n",
    "bert_embed_2 = BertEmbedding(vocab, layers='2,-1', model_dir_or_name='en-base-cased')\n",
    "print(bert_embed_2.embedding_dim)  # 1536\n",
    "stack_embed = StackEmbedding([static_embed, char_embed])\n",
    "print(stack_embed.embedding_dim)  # 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vocabulary file /remote-home/ynzheng/.fastNLP/embedding/bert-base-cased/vocab.txt\n",
      "Load pre-trained BERT parameters from file /remote-home/ynzheng/.fastNLP/embedding/bert-base-cased/pytorch_model.bin.\n",
      "Start to generate word pieces for word.\n",
      "Found(Or segment into word pieces) 7 words out of 7.\n"
     ]
    }
   ],
   "source": [
    "from fastNLP.embeddings import *\n",
    "\n",
    "vocab = Vocabulary()\n",
    "vocab.add_word_lst(\"this is a demo .\".split())\n",
    "\n",
    "embed = BertEmbedding(vocab, model_dir_or_name='en-base-cased', requires_grad=True)  # 初始化时设定为需要更新\n",
    "embed.requires_grad = False  # 修改BertEmbedding的权重为不更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3633, -0.2091, -0.0353, -0.3771, -0.5193]],\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "tensor([[ 0.0926, -0.4812, -0.7744,  0.4836, -0.5475]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "from fastNLP.embeddings import StaticEmbedding\n",
    "from fastNLP import Vocabulary\n",
    "\n",
    "vocab = Vocabulary().add_word_lst(\"The the a A\".split())\n",
    "#  下面用随机的StaticEmbedding演示，但与使用预训练词向量时效果是一致的\n",
    "embed = StaticEmbedding(vocab, model_name_or_dir=None, embedding_dim=5)\n",
    "print(embed(torch.LongTensor([vocab.to_index('The')])))\n",
    "print(embed(torch.LongTensor([vocab.to_index('the')])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All word in the vocab have been lowered. There are 6 words, 4 unique lowered words.\n",
      "tensor([[ 0.4530, -0.1558, -0.1941,  0.3203,  0.0355]],\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "tensor([[ 0.4530, -0.1558, -0.1941,  0.3203,  0.0355]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "from fastNLP.embeddings import StaticEmbedding\n",
    "from fastNLP import Vocabulary\n",
    "\n",
    "vocab = Vocabulary().add_word_lst(\"The the a A\".split())\n",
    "#  下面用随机的StaticEmbedding演示，但与使用预训练时效果是一致的\n",
    "embed = StaticEmbedding(vocab, model_name_or_dir=None, embedding_dim=5, lower=True)\n",
    "print(embed(torch.LongTensor([vocab.to_index('The')])))\n",
    "print(embed(torch.LongTensor([vocab.to_index('the')])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 4 words have frequency less than 2.\n",
      "tensor([[ 0.4724, -0.7277, -0.6350, -0.5258, -0.6063]],\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "tensor([[ 0.7638, -0.0552,  0.1625, -0.2210,  0.4993]],\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "tensor([[ 0.7638, -0.0552,  0.1625, -0.2210,  0.4993]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "from fastNLP.embeddings import StaticEmbedding\n",
    "from fastNLP import Vocabulary\n",
    "\n",
    "vocab = Vocabulary().add_word_lst(\"the the the a\".split())\n",
    "#  下面用随机的StaticEmbedding演示，但与使用预训练时效果是一致的\n",
    "embed = StaticEmbedding(vocab, model_name_or_dir=None, embedding_dim=5, min_freq=2)\n",
    "print(embed(torch.LongTensor([vocab.to_index('the')])))\n",
    "print(embed(torch.LongTensor([vocab.to_index('a')])))\n",
    "print(embed(torch.LongTensor([vocab.unknown_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 out of 5 words have frequency less than 2.\n",
      "All word in the vocab have been lowered. There are 5 words, 4 unique lowered words.\n",
      "tensor([[ 0.1943,  0.3739,  0.2769, -0.4746, -0.3181]],\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "tensor([[ 0.5892, -0.6916,  0.7319, -0.3803,  0.4979]],\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "tensor([[ 0.5892, -0.6916,  0.7319, -0.3803,  0.4979]],\n",
      "       grad_fn=<EmbeddingBackward>)\n",
      "tensor([[-0.1348, -0.2172, -0.0071,  0.5704, -0.2607]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "from fastNLP.embeddings import StaticEmbedding\n",
    "from fastNLP import Vocabulary\n",
    "\n",
    "vocab = Vocabulary().add_word_lst(\"the the the a A\".split())\n",
    "#  下面用随机的StaticEmbedding演示，但与使用预训练时效果是一致的\n",
    "embed = StaticEmbedding(vocab, model_name_or_dir=None, embedding_dim=5, min_freq=2, lower=True)\n",
    "print(embed(torch.LongTensor([vocab.to_index('the')])))\n",
    "print(embed(torch.LongTensor([vocab.to_index('a')])))\n",
    "print(embed(torch.LongTensor([vocab.to_index('A')])))\n",
    "print(embed(torch.LongTensor([vocab.unknown_idx])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
