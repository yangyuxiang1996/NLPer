### 预备知识

**document**（文档）：在gensim中，document指的是文本序列类型的对象，在python3中也被看作是str类型

**corpus**（语料）：corpus是document对象的集合，在gensim中，corpus扮演两种角色：

* 模型训练的输入
* 待整理的document

当待处理的语料比较庞大时，corpus可以支持流式处理，"one document at a time"

**vector（向量）**：文档document的数学表示，表示方法包括：bag-of-words

**model（模型）**：将vectors从一种表示转换成另一种表示的算法，包括tf-idf 

### Bag-of-words model

词袋模型

将文档去除相应的停用词、特殊字符后，得到包含所有单词的词典

将每一条文档转换成向量，向量的维度是词典的长度，向量中的每一个元素为该单词在该文档中出现的频率；

### TF-IDF

term frequency-inverse document frequency(TF-IDF)是一种用于信息检索和数据挖掘的常用加权技术，常用于挖掘文本的关键词，算法简单高效，常被用于最开始的文本数据清洗。

TF: 词频；IDF：逆文档频率

某个词在一个文档中的TF-IDF值越大，说明这个词在这篇文档中的重要性越高，所以痛殴计算文章中的各个词的TF-IDF值，由大到小排序，就可以得到该文章的关键词。
$$
\text{TF}=\frac{\text{某个词在文章中出现的总次数}}{文章的总词数}
$$

$$
\text{IDF}=\log(\frac{语料库的文档总数}{\text{包含该词的文档数+1}})
$$

$$
\text{TF-IDF}=\text{TF} \times \text{IDF}
$$

### Latent Semantic Analysis

Latent Semantic Analysis，潜在语义分析，是语义学的一个新的分支。模型的输入是由任何一种语言书写的文献构成的文库，输出是该语言的字、词的一种数学表达（向量）。潜在语义学的观念被应用在资讯索引上，有时潜在语义学也被称为隐含语义索引。

核心思想：

假设有n篇文档，经过分词、去词根、去停止词等操作后的单词总数为m，可以用一个m*n的矩阵X来表示这些文档，这个矩阵的每个元素$X_{i,j}$表示第i个单词在第j篇文档中出现的次数（也可以用tf-idf值来表示）。LSA试图将原始矩阵降维到一个潜在的概念空间，然后每个单词或文档都可以用该空间下的一组权值向量（坐标）来表示，这些权重反应了与对应的多潜在概念的关联程度的强弱。

这个降维通过对矩阵进行奇异值分解（SVD）做到的，公式如下：
$$
X=U\Sigma V^T
$$
其中 U 为 `m * n` 维，Σ为对角阵 `n * n` 维，V 为 `n * n` 维。
Σ 矩阵中对角线上的每一个值就是SVD过程中得到的奇异值，其大小反映了其对应的潜在概念的重要程度。
然后我们可以自行设定降维后的潜在概念的维度 k(k<n) , 可以得到：
$$
X_k=U_k\Sigma_k V_k^T
$$
其中 Uk 是将 U仅保留前 k 列的结果，Σk 是仅保留前 k 行及前 k 列的结果，Vk 是将 V 仅保留前 k 列的结果。Xk 则是将 X 降维到 k 维的近似结果，这个 k 越接近n, Xk 与 X 也越接近，但我们的目标并不是越接近越好，LSA认为 k 值不宜过大（保留了冗余的潜在概念）也不宜过小。

## 常用接口：

word2vec

LDA

Dictionary

